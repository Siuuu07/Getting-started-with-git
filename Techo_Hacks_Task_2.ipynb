{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e5751d",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:31.426968Z",
          "iopub.status.busy": "2024-02-28T18:48:31.426024Z",
          "iopub.status.idle": "2024-02-28T18:48:32.475561Z",
          "shell.execute_reply": "2024-02-28T18:48:32.474644Z"
        },
        "papermill": {
          "duration": 1.058933,
          "end_time": "2024-02-28T18:48:32.477565",
          "exception": false,
          "start_time": "2024-02-28T18:48:31.418632",
          "status": "completed"
        },
        "tags": [],
        "id": "31e5751d",
        "outputId": "27f988d9-a0c1-41da-dabb-54e006a12f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/twitter-airline-sentiment/Tweets.csv\n",
            "/kaggle/input/twitter-airline-sentiment/database.sqlite\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c942e74",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.490153Z",
          "iopub.status.busy": "2024-02-28T18:48:32.489193Z",
          "iopub.status.idle": "2024-02-28T18:48:32.622153Z",
          "shell.execute_reply": "2024-02-28T18:48:32.620708Z"
        },
        "papermill": {
          "duration": 0.141913,
          "end_time": "2024-02-28T18:48:32.624804",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.482891",
          "status": "completed"
        },
        "tags": [],
        "id": "8c942e74"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\n",
        "df1\n",
        "\n",
        "df2 = df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1cc2208",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.636329Z",
          "iopub.status.busy": "2024-02-28T18:48:32.635990Z",
          "iopub.status.idle": "2024-02-28T18:48:32.675522Z",
          "shell.execute_reply": "2024-02-28T18:48:32.674319Z"
        },
        "papermill": {
          "duration": 0.047633,
          "end_time": "2024-02-28T18:48:32.677485",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.629852",
          "status": "completed"
        },
        "tags": [],
        "id": "c1cc2208",
        "outputId": "22479c87-dfe3-4e74-f93b-9e1b6a2e9dfc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>retweet_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.464000e+04</td>\n",
              "      <td>14640.000000</td>\n",
              "      <td>10522.000000</td>\n",
              "      <td>14640.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.692184e+17</td>\n",
              "      <td>0.900169</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.082650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.791112e+14</td>\n",
              "      <td>0.162830</td>\n",
              "      <td>0.330440</td>\n",
              "      <td>0.745778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.675883e+17</td>\n",
              "      <td>0.335000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.685592e+17</td>\n",
              "      <td>0.692300</td>\n",
              "      <td>0.360600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.694779e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.670600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.698905e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.703106e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
              "count  1.464000e+04                  14640.000000               10522.000000   \n",
              "mean   5.692184e+17                      0.900169                   0.638298   \n",
              "std    7.791112e+14                      0.162830                   0.330440   \n",
              "min    5.675883e+17                      0.335000                   0.000000   \n",
              "25%    5.685592e+17                      0.692300                   0.360600   \n",
              "50%    5.694779e+17                      1.000000                   0.670600   \n",
              "75%    5.698905e+17                      1.000000                   1.000000   \n",
              "max    5.703106e+17                      1.000000                   1.000000   \n",
              "\n",
              "       retweet_count  \n",
              "count   14640.000000  \n",
              "mean        0.082650  \n",
              "std         0.745778  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max        44.000000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd578ae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.690004Z",
          "iopub.status.busy": "2024-02-28T18:48:32.688954Z",
          "iopub.status.idle": "2024-02-28T18:48:32.716093Z",
          "shell.execute_reply": "2024-02-28T18:48:32.714766Z"
        },
        "papermill": {
          "duration": 0.035649,
          "end_time": "2024-02-28T18:48:32.718410",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.682761",
          "status": "completed"
        },
        "tags": [],
        "id": "3dd578ae",
        "outputId": "63944063-7a30-4dc5-ef14-5c973939b7d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14640 entries, 0 to 14639\n",
            "Data columns (total 15 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   tweet_id                      14640 non-null  int64  \n",
            " 1   airline_sentiment             14640 non-null  object \n",
            " 2   airline_sentiment_confidence  14640 non-null  float64\n",
            " 3   negativereason                9178 non-null   object \n",
            " 4   negativereason_confidence     10522 non-null  float64\n",
            " 5   airline                       14640 non-null  object \n",
            " 6   airline_sentiment_gold        40 non-null     object \n",
            " 7   name                          14640 non-null  object \n",
            " 8   negativereason_gold           32 non-null     object \n",
            " 9   retweet_count                 14640 non-null  int64  \n",
            " 10  text                          14640 non-null  object \n",
            " 11  tweet_coord                   1019 non-null   object \n",
            " 12  tweet_created                 14640 non-null  object \n",
            " 13  tweet_location                9907 non-null   object \n",
            " 14  user_timezone                 9820 non-null   object \n",
            "dtypes: float64(2), int64(2), object(11)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33851b1d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.731183Z",
          "iopub.status.busy": "2024-02-28T18:48:32.730801Z",
          "iopub.status.idle": "2024-02-28T18:48:32.738883Z",
          "shell.execute_reply": "2024-02-28T18:48:32.738003Z"
        },
        "papermill": {
          "duration": 0.017428,
          "end_time": "2024-02-28T18:48:32.741237",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.723809",
          "status": "completed"
        },
        "tags": [],
        "id": "33851b1d"
      },
      "outputs": [],
      "source": [
        "df1 = df1[['airline_sentiment', 'text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8769b61e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.753187Z",
          "iopub.status.busy": "2024-02-28T18:48:32.752828Z",
          "iopub.status.idle": "2024-02-28T18:48:32.774802Z",
          "shell.execute_reply": "2024-02-28T18:48:32.773753Z"
        },
        "papermill": {
          "duration": 0.030695,
          "end_time": "2024-02-28T18:48:32.777219",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.746524",
          "status": "completed"
        },
        "tags": [],
        "id": "8769b61e",
        "outputId": "065654ff-8b96-4525-edf5-a0f22e1b34b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_18/1729734181.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].str.lower()\n",
            "/tmp/ipykernel_18/1729734181.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['airline_sentiment']  = df['airline_sentiment'].str.lower()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@virginamerica what @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@virginamerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@virginamerica i didn't today... must mean i n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@virginamerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@virginamerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>positive</td>\n",
              "      <td>@americanair thank you we got on a different f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14636</th>\n",
              "      <td>negative</td>\n",
              "      <td>@americanair leaving over 20 minutes late flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14637</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@americanair please bring american airlines to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14638</th>\n",
              "      <td>negative</td>\n",
              "      <td>@americanair you have my money, you change my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14639</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@americanair we have 8 ppl so we need 2 know h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14640 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment                                               text\n",
              "0               neutral                @virginamerica what @dhepburn said.\n",
              "1              positive  @virginamerica plus you've added commercials t...\n",
              "2               neutral  @virginamerica i didn't today... must mean i n...\n",
              "3              negative  @virginamerica it's really aggressive to blast...\n",
              "4              negative  @virginamerica and it's a really big bad thing...\n",
              "...                 ...                                                ...\n",
              "14635          positive  @americanair thank you we got on a different f...\n",
              "14636          negative  @americanair leaving over 20 minutes late flig...\n",
              "14637           neutral  @americanair please bring american airlines to...\n",
              "14638          negative  @americanair you have my money, you change my ...\n",
              "14639           neutral  @americanair we have 8 ppl so we need 2 know h...\n",
              "\n",
              "[14640 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df1\n",
        "df['text'] = df['text'].str.lower()\n",
        "df['airline_sentiment']  = df['airline_sentiment'].str.lower()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f50e3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.791826Z",
          "iopub.status.busy": "2024-02-28T18:48:32.790352Z",
          "iopub.status.idle": "2024-02-28T18:48:32.801933Z",
          "shell.execute_reply": "2024-02-28T18:48:32.800196Z"
        },
        "papermill": {
          "duration": 0.021067,
          "end_time": "2024-02-28T18:48:32.804287",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.783220",
          "status": "completed"
        },
        "tags": [],
        "id": "e3f50e3f"
      },
      "outputs": [],
      "source": [
        "# Example contractions dictionary\n",
        "contractions_dict = {\n",
        "  \"ain't\": \"am not\",\n",
        "  \"aren't\": \"are not\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"he'll\": \"he will\",\n",
        "  \"here's\": \"here is\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"i'd\": \"i would\",\n",
        "  \"i'll\": \"i will\",\n",
        "  \"i'm\": \"i am\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it's\": \"it is\",\n",
        "  \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'll\": \"she will\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",\n",
        "  \"this's\": \"this is\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we would\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"you'd\": \"you would\",\n",
        "  \"you'll\": \"you will\",\n",
        "  \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "def expand_contractions(text, contractions_dict):\n",
        "  \"\"\"\n",
        "  Expands contractions in text using a dictionary.\n",
        "\n",
        "  Args:\n",
        "    text: The text to be processed.\n",
        "    contractions_dict: A dictionary of contractions and their expansions.\n",
        "\n",
        "  Returns:\n",
        "    The expanded text.\n",
        "  \"\"\"\n",
        "  expanded_text = []\n",
        "  for word in text.split():\n",
        "    if word.lower() in contractions_dict:\n",
        "      expanded_text.append(contractions_dict[word.lower()])\n",
        "    else:\n",
        "      expanded_text.append(word)\n",
        "  return \" \".join(expanded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c40a447",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.817047Z",
          "iopub.status.busy": "2024-02-28T18:48:32.816683Z",
          "iopub.status.idle": "2024-02-28T18:48:32.906200Z",
          "shell.execute_reply": "2024-02-28T18:48:32.904989Z"
        },
        "papermill": {
          "duration": 0.098383,
          "end_time": "2024-02-28T18:48:32.908222",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.809839",
          "status": "completed"
        },
        "tags": [],
        "id": "2c40a447",
        "outputId": "86e1bb50-9496-4d1e-db80-5aefffa1c6ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_18/554856839.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(expand_contractions, args=(contractions_dict,))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@virginamerica what @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@virginamerica plus you have added commercials...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@virginamerica i did not today... must mean i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@virginamerica it is really aggressive to blas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@virginamerica and it is a really big bad thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>positive</td>\n",
              "      <td>@americanair thank you we got on a different f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14636</th>\n",
              "      <td>negative</td>\n",
              "      <td>@americanair leaving over 20 minutes late flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14637</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@americanair please bring american airlines to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14638</th>\n",
              "      <td>negative</td>\n",
              "      <td>@americanair you have my money, you change my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14639</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@americanair we have 8 ppl so we need 2 know h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14640 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment                                               text\n",
              "0               neutral                @virginamerica what @dhepburn said.\n",
              "1              positive  @virginamerica plus you have added commercials...\n",
              "2               neutral  @virginamerica i did not today... must mean i ...\n",
              "3              negative  @virginamerica it is really aggressive to blas...\n",
              "4              negative  @virginamerica and it is a really big bad thin...\n",
              "...                 ...                                                ...\n",
              "14635          positive  @americanair thank you we got on a different f...\n",
              "14636          negative  @americanair leaving over 20 minutes late flig...\n",
              "14637           neutral  @americanair please bring american airlines to...\n",
              "14638          negative  @americanair you have my money, you change my ...\n",
              "14639           neutral  @americanair we have 8 ppl so we need 2 know h...\n",
              "\n",
              "[14640 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].apply(expand_contractions, args=(contractions_dict,))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed800544",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:32.922254Z",
          "iopub.status.busy": "2024-02-28T18:48:32.921851Z",
          "iopub.status.idle": "2024-02-28T18:48:38.276071Z",
          "shell.execute_reply": "2024-02-28T18:48:38.274641Z"
        },
        "papermill": {
          "duration": 5.363648,
          "end_time": "2024-02-28T18:48:38.277967",
          "exception": false,
          "start_time": "2024-02-28T18:48:32.914319",
          "status": "completed"
        },
        "tags": [],
        "id": "ed800544",
        "outputId": "ace295cf-26af-41ca-a88e-05843b6b80c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_18/7797780.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text_tokened'] = df['text'].apply(word_tokenize)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>text_tokened</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@virginamerica what @dhepburn said.</td>\n",
              "      <td>[@, virginamerica, what, @, dhepburn, said, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@virginamerica plus you have added commercials...</td>\n",
              "      <td>[@, virginamerica, plus, you, have, added, com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@virginamerica i did not today... must mean i ...</td>\n",
              "      <td>[@, virginamerica, i, did, not, today, ..., mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@virginamerica it is really aggressive to blas...</td>\n",
              "      <td>[@, virginamerica, it, is, really, aggressive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@virginamerica and it is a really big bad thin...</td>\n",
              "      <td>[@, virginamerica, and, it, is, a, really, big...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>positive</td>\n",
              "      <td>@americanair thank you we got on a different f...</td>\n",
              "      <td>[@, americanair, thank, you, we, got, on, a, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14636</th>\n",
              "      <td>negative</td>\n",
              "      <td>@americanair leaving over 20 minutes late flig...</td>\n",
              "      <td>[@, americanair, leaving, over, 20, minutes, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14637</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@americanair please bring american airlines to...</td>\n",
              "      <td>[@, americanair, please, bring, american, airl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14638</th>\n",
              "      <td>negative</td>\n",
              "      <td>@americanair you have my money, you change my ...</td>\n",
              "      <td>[@, americanair, you, have, my, money, ,, you,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14639</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@americanair we have 8 ppl so we need 2 know h...</td>\n",
              "      <td>[@, americanair, we, have, 8, ppl, so, we, nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14640 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment                                               text  \\\n",
              "0               neutral                @virginamerica what @dhepburn said.   \n",
              "1              positive  @virginamerica plus you have added commercials...   \n",
              "2               neutral  @virginamerica i did not today... must mean i ...   \n",
              "3              negative  @virginamerica it is really aggressive to blas...   \n",
              "4              negative  @virginamerica and it is a really big bad thin...   \n",
              "...                 ...                                                ...   \n",
              "14635          positive  @americanair thank you we got on a different f...   \n",
              "14636          negative  @americanair leaving over 20 minutes late flig...   \n",
              "14637           neutral  @americanair please bring american airlines to...   \n",
              "14638          negative  @americanair you have my money, you change my ...   \n",
              "14639           neutral  @americanair we have 8 ppl so we need 2 know h...   \n",
              "\n",
              "                                            text_tokened  \n",
              "0         [@, virginamerica, what, @, dhepburn, said, .]  \n",
              "1      [@, virginamerica, plus, you, have, added, com...  \n",
              "2      [@, virginamerica, i, did, not, today, ..., mu...  \n",
              "3      [@, virginamerica, it, is, really, aggressive,...  \n",
              "4      [@, virginamerica, and, it, is, a, really, big...  \n",
              "...                                                  ...  \n",
              "14635  [@, americanair, thank, you, we, got, on, a, d...  \n",
              "14636  [@, americanair, leaving, over, 20, minutes, l...  \n",
              "14637  [@, americanair, please, bring, american, airl...  \n",
              "14638  [@, americanair, you, have, my, money, ,, you,...  \n",
              "14639  [@, americanair, we, have, 8, ppl, so, we, nee...  \n",
              "\n",
              "[14640 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# df['text'] = df['text'].str.lower()\n",
        "df['text_tokened'] = df['text'].apply(word_tokenize)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e3339d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:38.291456Z",
          "iopub.status.busy": "2024-02-28T18:48:38.291149Z",
          "iopub.status.idle": "2024-02-28T18:48:38.302032Z",
          "shell.execute_reply": "2024-02-28T18:48:38.300828Z"
        },
        "papermill": {
          "duration": 0.019853,
          "end_time": "2024-02-28T18:48:38.303989",
          "exception": false,
          "start_time": "2024-02-28T18:48:38.284136",
          "status": "completed"
        },
        "tags": [],
        "id": "61e3339d",
        "outputId": "abb8896b-166b-45b9-a1d4-ba70492caaf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['virgin america', 'united', 'southwest', 'delta', 'us airways', 'american']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To replace the mention with people or airline, we need the list of airlines, we can grab airlines from the first daaframe\n",
        "airlines = df2['airline'].str.lower().unique().tolist()\n",
        "airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62954a25",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:38.318664Z",
          "iopub.status.busy": "2024-02-28T18:48:38.318358Z",
          "iopub.status.idle": "2024-02-28T18:48:38.324414Z",
          "shell.execute_reply": "2024-02-28T18:48:38.322966Z"
        },
        "papermill": {
          "duration": 0.016574,
          "end_time": "2024-02-28T18:48:38.326749",
          "exception": false,
          "start_time": "2024-02-28T18:48:38.310175",
          "status": "completed"
        },
        "tags": [],
        "id": "62954a25"
      },
      "outputs": [],
      "source": [
        "def replace_with_person_or_airline(text_tokens, airlines_dict):\n",
        "    for i in range(len(text_tokens)):\n",
        "        if text_tokens[i] == '@' and text_tokens[i+1] in airlines_dict:\n",
        "            text_tokens[i+1] = \"airline\"\n",
        "            i += 2  # Skip next word as well\n",
        "        elif text_tokens[i] == '@':\n",
        "            text_tokens[i+1] = \"person\"\n",
        "            i += 2  # Skip next word as well\n",
        "    return text_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1612d44",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:38.340846Z",
          "iopub.status.busy": "2024-02-28T18:48:38.340467Z",
          "iopub.status.idle": "2024-02-28T18:48:38.406822Z",
          "shell.execute_reply": "2024-02-28T18:48:38.405534Z"
        },
        "papermill": {
          "duration": 0.076544,
          "end_time": "2024-02-28T18:48:38.409545",
          "exception": false,
          "start_time": "2024-02-28T18:48:38.333001",
          "status": "completed"
        },
        "tags": [],
        "id": "b1612d44",
        "outputId": "94479b95-1cc5-4f0f-e3e1-ef784b81e630"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_18/1726309089.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['cleaned'] = df['text_tokened'].apply(replace_with_person_or_airline,args=(airlines,))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0                    [@, person, what, @, person, said, .]\n",
              "1        [@, person, plus, you, have, added, commercial...\n",
              "2        [@, person, i, did, not, today, ..., must, mea...\n",
              "3        [@, person, it, is, really, aggressive, to, bl...\n",
              "4        [@, person, and, it, is, a, really, big, bad, ...\n",
              "                               ...                        \n",
              "14635    [@, person, thank, you, we, got, on, a, differ...\n",
              "14636    [@, person, leaving, over, 20, minutes, late, ...\n",
              "14637    [@, person, please, bring, american, airlines,...\n",
              "14638    [@, person, you, have, my, money, ,, you, chan...\n",
              "14639    [@, person, we, have, 8, ppl, so, we, need, 2,...\n",
              "Name: cleaned, Length: 14640, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['cleaned'] = df['text_tokened'].apply(replace_with_person_or_airline,args=(airlines,))\n",
        "df['cleaned']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae4b0d1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:38.424191Z",
          "iopub.status.busy": "2024-02-28T18:48:38.423834Z",
          "iopub.status.idle": "2024-02-28T18:48:38.477555Z",
          "shell.execute_reply": "2024-02-28T18:48:38.476063Z"
        },
        "papermill": {
          "duration": 0.064003,
          "end_time": "2024-02-28T18:48:38.480087",
          "exception": false,
          "start_time": "2024-02-28T18:48:38.416084",
          "status": "completed"
        },
        "tags": [],
        "id": "1ae4b0d1",
        "outputId": "4c1d010f-546d-4210-bc83-366508917150"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_18/2808321106.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['cleaned'] = df['text_tokened'].apply(lambda x:[y for y in x if y != '@'])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0                          [person, what, person, said, .]\n",
              "1        [person, plus, you, have, added, commercials, ...\n",
              "2        [person, i, did, not, today, ..., must, mean, ...\n",
              "3        [person, it, is, really, aggressive, to, blast...\n",
              "4        [person, and, it, is, a, really, big, bad, thi...\n",
              "                               ...                        \n",
              "14635    [person, thank, you, we, got, on, a, different...\n",
              "14636    [person, leaving, over, 20, minutes, late, fli...\n",
              "14637    [person, please, bring, american, airlines, to...\n",
              "14638    [person, you, have, my, money, ,, you, change,...\n",
              "14639    [person, we, have, 8, ppl, so, we, need, 2, kn...\n",
              "Name: cleaned, Length: 14640, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['cleaned'] = df['text_tokened'].apply(lambda x:[y for y in x if y != '@'])\n",
        "df['cleaned']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d8388f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:38.494982Z",
          "iopub.status.busy": "2024-02-28T18:48:38.494598Z",
          "iopub.status.idle": "2024-02-28T18:48:52.586657Z",
          "shell.execute_reply": "2024-02-28T18:48:52.586008Z"
        },
        "papermill": {
          "duration": 14.101689,
          "end_time": "2024-02-28T18:48:52.588581",
          "exception": false,
          "start_time": "2024-02-28T18:48:38.486892",
          "status": "completed"
        },
        "tags": [],
        "id": "a7d8388f",
        "outputId": "ac2b33af-b359-435c-8415-45057c77d2f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-28 18:48:40.623196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-28 18:48:40.623356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-28 18:48:40.796985: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "16464"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['cleaned'])\n",
        "\n",
        "# Convert text to sequences of numbers\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned'])\n",
        "vocab_size = len(tokenizer.index_word)\n",
        "# number of unique words in dataset\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915450d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:52.606167Z",
          "iopub.status.busy": "2024-02-28T18:48:52.604966Z",
          "iopub.status.idle": "2024-02-28T18:48:52.662345Z",
          "shell.execute_reply": "2024-02-28T18:48:52.660502Z"
        },
        "papermill": {
          "duration": 0.068202,
          "end_time": "2024-02-28T18:48:52.664440",
          "exception": false,
          "start_time": "2024-02-28T18:48:52.596238",
          "status": "completed"
        },
        "tags": [],
        "id": "915450d4",
        "outputId": "6393d7c6-c069-4443-efd4-48be34b5f629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14640, 46)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.utils import pad_sequences\n",
        "sequences = pad_sequences(sequences, padding='pre')\n",
        "sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9999604b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:52.680466Z",
          "iopub.status.busy": "2024-02-28T18:48:52.680167Z",
          "iopub.status.idle": "2024-02-28T18:48:52.690212Z",
          "shell.execute_reply": "2024-02-28T18:48:52.689273Z"
        },
        "papermill": {
          "duration": 0.020498,
          "end_time": "2024-02-28T18:48:52.691992",
          "exception": false,
          "start_time": "2024-02-28T18:48:52.671494",
          "status": "completed"
        },
        "tags": [],
        "id": "9999604b",
        "outputId": "06093d14-da46-4cf6-8d19-ae7b291b15c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_18/1138143624.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['airline_sentiment_labelencoded'] = le.fit_transform(df['airline_sentiment'])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "df['airline_sentiment_labelencoded'] = le.fit_transform(df['airline_sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff097e6e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:52.707953Z",
          "iopub.status.busy": "2024-02-28T18:48:52.707536Z",
          "iopub.status.idle": "2024-02-28T18:48:52.717918Z",
          "shell.execute_reply": "2024-02-28T18:48:52.716210Z"
        },
        "papermill": {
          "duration": 0.021737,
          "end_time": "2024-02-28T18:48:52.720979",
          "exception": false,
          "start_time": "2024-02-28T18:48:52.699242",
          "status": "completed"
        },
        "tags": [],
        "id": "ff097e6e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sequences, df['airline_sentiment_labelencoded'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58f26bf1",
      "metadata": {
        "papermill": {
          "duration": 0.008035,
          "end_time": "2024-02-28T18:48:52.736203",
          "exception": false,
          "start_time": "2024-02-28T18:48:52.728168",
          "status": "completed"
        },
        "tags": [],
        "id": "58f26bf1"
      },
      "source": [
        "## Simple RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ca0d73",
      "metadata": {
        "papermill": {
          "duration": 0.006914,
          "end_time": "2024-02-28T18:48:52.750418",
          "exception": false,
          "start_time": "2024-02-28T18:48:52.743504",
          "status": "completed"
        },
        "tags": [],
        "id": "49ca0d73"
      },
      "source": [
        "input_dim = size of the vocabulary\n",
        "input_length = 46 words (if the tweet was shorter, it was padded. If longer, it is truncated\n",
        "output_dim = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315283e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:52.770362Z",
          "iopub.status.busy": "2024-02-28T18:48:52.769499Z",
          "iopub.status.idle": "2024-02-28T18:48:53.089900Z",
          "shell.execute_reply": "2024-02-28T18:48:53.087983Z"
        },
        "papermill": {
          "duration": 0.333905,
          "end_time": "2024-02-28T18:48:53.092298",
          "exception": false,
          "start_time": "2024-02-28T18:48:52.758393",
          "status": "completed"
        },
        "tags": [],
        "id": "315283e7",
        "outputId": "28a6b02d-6d93-499c-c9b3-2b40dfd145c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 46, 2)             32930     \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 106)               5936      \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 106)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12)                1284      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 39        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40189 (156.99 KB)\n",
            "Trainable params: 40189 (156.99 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Bidirectional, SimpleRNN,GRU,LSTM,Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=16465,output_dim=2,input_length=46),\n",
        "    Bidirectional(SimpleRNN(53)),\n",
        "    Dropout(0.5),\n",
        "    Dense(12,activation='relu'),\n",
        "    Dense(3,activation='softmax')\n",
        "])\n",
        "\n",
        "#compiling model\n",
        "model.compile(optimizer=\"rmsprop\",loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55243ff1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:48:53.110317Z",
          "iopub.status.busy": "2024-02-28T18:48:53.109928Z",
          "iopub.status.idle": "2024-02-28T18:50:18.579264Z",
          "shell.execute_reply": "2024-02-28T18:50:18.577896Z"
        },
        "papermill": {
          "duration": 85.481657,
          "end_time": "2024-02-28T18:50:18.582257",
          "exception": false,
          "start_time": "2024-02-28T18:48:53.100600",
          "status": "completed"
        },
        "tags": [],
        "id": "55243ff1",
        "outputId": "cfaac2b9-f2a5-444e-b0fb-92a45dc00ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "366/366 [==============================] - 7s 15ms/step - loss: 0.8683 - accuracy: 0.6160 - val_loss: 0.7313 - val_accuracy: 0.6844\n",
            "Epoch 2/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.7003 - accuracy: 0.6966 - val_loss: 0.6573 - val_accuracy: 0.7324\n",
            "Epoch 3/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.6258 - accuracy: 0.7299 - val_loss: 0.6094 - val_accuracy: 0.7434\n",
            "Epoch 4/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.5802 - accuracy: 0.7534 - val_loss: 0.6435 - val_accuracy: 0.7485\n",
            "Epoch 5/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.5439 - accuracy: 0.7750 - val_loss: 0.5620 - val_accuracy: 0.7746\n",
            "Epoch 6/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.5137 - accuracy: 0.7906 - val_loss: 0.5644 - val_accuracy: 0.7738\n",
            "Epoch 7/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.4919 - accuracy: 0.8047 - val_loss: 0.5805 - val_accuracy: 0.7672\n",
            "Epoch 8/16\n",
            "366/366 [==============================] - 5s 15ms/step - loss: 0.4678 - accuracy: 0.8160 - val_loss: 0.5931 - val_accuracy: 0.7749\n",
            "Epoch 9/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.4440 - accuracy: 0.8287 - val_loss: 0.5414 - val_accuracy: 0.7907\n",
            "Epoch 10/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.4284 - accuracy: 0.8389 - val_loss: 0.5565 - val_accuracy: 0.7907\n",
            "Epoch 11/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.4091 - accuracy: 0.8432 - val_loss: 0.5448 - val_accuracy: 0.7819\n",
            "Epoch 12/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.3959 - accuracy: 0.8578 - val_loss: 0.5732 - val_accuracy: 0.7867\n",
            "Epoch 13/16\n",
            "366/366 [==============================] - 6s 15ms/step - loss: 0.3826 - accuracy: 0.8589 - val_loss: 0.5551 - val_accuracy: 0.7944\n",
            "Epoch 14/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.3674 - accuracy: 0.8654 - val_loss: 0.5564 - val_accuracy: 0.7914\n",
            "Epoch 15/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.3585 - accuracy: 0.8677 - val_loss: 0.5725 - val_accuracy: 0.7768\n",
            "Epoch 16/16\n",
            "366/366 [==============================] - 5s 14ms/step - loss: 0.3508 - accuracy: 0.8700 - val_loss: 0.5421 - val_accuracy: 0.7914\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=16, validation_data = (X_test[:-200], y_test[:-200]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb1f0f3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T18:50:18.766035Z",
          "iopub.status.busy": "2024-02-28T18:50:18.765166Z",
          "iopub.status.idle": "2024-02-28T18:50:19.102277Z",
          "shell.execute_reply": "2024-02-28T18:50:19.100724Z"
        },
        "papermill": {
          "duration": 0.430905,
          "end_time": "2024-02-28T18:50:19.104748",
          "exception": false,
          "start_time": "2024-02-28T18:50:18.673843",
          "status": "completed"
        },
        "tags": [],
        "id": "ffb1f0f3",
        "outputId": "7aef4200-1b33-41e3-a9c3-61e1612ba59c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n",
            "Accuracy: 0.855\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test data\n",
        "predictions = model.predict(X_test[-200:])\n",
        "# Now evaluate the model using metrics like accuracy, precision, recall, etc.\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Convert predictions to class labels (assuming predictions are in one-hot encoded format)\n",
        "predicted_labels = predictions.argmax(axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test[-200:], predicted_labels) # GRADING, COMPARING YOUR ANSWERS TO SOLUTION KEY\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 17,
          "sourceId": 742210,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 113.090752,
      "end_time": "2024-02-28T18:50:21.828664",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-28T18:48:28.737912",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}